{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from sklearn.datasets import load_boston\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn import metrics\n",
    "#from sklearn import preprocessing\n",
    "#import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载波士顿房价的数据\n",
    "data = load_boston()\n",
    "train = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "train['price'] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'506'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看有多少个样本\n",
    "format(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据类型\n",
    "#train.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看空值\n",
    "#train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据大小\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       price  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据描述\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.388305\n",
       "ZN         0.360445\n",
       "INDUS     -0.483725\n",
       "CHAS       0.175260\n",
       "NOX       -0.427321\n",
       "RM         0.695360\n",
       "AGE       -0.376955\n",
       "DIS        0.249929\n",
       "RAD       -0.381626\n",
       "TAX       -0.468536\n",
       "PTRATIO   -0.507787\n",
       "B          0.333461\n",
       "LSTAT     -0.737663\n",
       "price      1.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以具体看看前面 5 个训练集长什么样子，可以看到，前面都是这个房屋的属性，最后是房屋的价格\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#我们取出第二个特征到倒数第二个特征，这些特征作为我们神经网络的输入特征\n",
    "all_features = train.loc[:,'CRIM':'LSTAT']\n",
    "#接着我们需要进行数据标准化，对于所有的数值特征，我们都会减去均值，除以方差\n",
    "numeric_feats = all_features.dtypes[all_features.dtypes != \"object\"].index # 取出所有的数值特征\n",
    "# 减去均值，除以方差\n",
    "all_features[numeric_feats] = all_features[numeric_feats].apply(lambda x: (x - x.mean()) \n",
    "                                                                / (x.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_train = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419367</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>-1.286636</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>0.413263</td>\n",
       "      <td>-0.119895</td>\n",
       "      <td>0.140075</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.665949</td>\n",
       "      <td>-1.457558</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.074499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.416927</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>0.194082</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.491953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.416929</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>1.281446</td>\n",
       "      <td>-0.265549</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.396035</td>\n",
       "      <td>-1.207532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416338</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.015298</td>\n",
       "      <td>-0.809088</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.415751</td>\n",
       "      <td>-1.360171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412074</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.227362</td>\n",
       "      <td>-0.510674</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.025487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.412820</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>0.438881</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>-0.625178</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.386834</td>\n",
       "      <td>-0.417734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.414839</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>-0.234316</td>\n",
       "      <td>0.288648</td>\n",
       "      <td>-0.715931</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.500355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.413038</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>0.983986</td>\n",
       "      <td>0.796661</td>\n",
       "      <td>-0.772919</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.982076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.407361</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>0.724955</td>\n",
       "      <td>0.736268</td>\n",
       "      <td>-0.667776</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.402826</td>\n",
       "      <td>-0.864446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.414590</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>-0.362408</td>\n",
       "      <td>0.434302</td>\n",
       "      <td>-0.612640</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.668397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.419367  0.284548 -1.286636 -0.272329 -0.144075  0.413263 -0.119895   \n",
       "1   -0.416927 -0.487240 -0.592794 -0.272329 -0.739530  0.194082  0.366803   \n",
       "2   -0.416929 -0.487240 -0.592794 -0.272329 -0.739530  1.281446 -0.265549   \n",
       "3   -0.416338 -0.487240 -1.305586 -0.272329 -0.834458  1.015298 -0.809088   \n",
       "4   -0.412074 -0.487240 -1.305586 -0.272329 -0.834458  1.227362 -0.510674   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501 -0.412820 -0.487240  0.115624 -0.272329  0.157968  0.438881  0.018654   \n",
       "502 -0.414839 -0.487240  0.115624 -0.272329  0.157968 -0.234316  0.288648   \n",
       "503 -0.413038 -0.487240  0.115624 -0.272329  0.157968  0.983986  0.796661   \n",
       "504 -0.407361 -0.487240  0.115624 -0.272329  0.157968  0.724955  0.736268   \n",
       "505 -0.414590 -0.487240  0.115624 -0.272329  0.157968 -0.362408  0.434302   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.140075 -0.981871 -0.665949 -1.457558  0.440616 -1.074499  \n",
       "1    0.556609 -0.867024 -0.986353 -0.302794  0.440616 -0.491953  \n",
       "2    0.556609 -0.867024 -0.986353 -0.302794  0.396035 -1.207532  \n",
       "3    1.076671 -0.752178 -1.105022  0.112920  0.415751 -1.360171  \n",
       "4    1.076671 -0.752178 -1.105022  0.112920  0.440616 -1.025487  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "501 -0.625178 -0.981871 -0.802418  1.175303  0.386834 -0.417734  \n",
       "502 -0.715931 -0.981871 -0.802418  1.175303  0.440616 -0.500355  \n",
       "503 -0.772919 -0.981871 -0.802418  1.175303  0.440616 -0.982076  \n",
       "504 -0.667776 -0.981871 -0.802418  1.175303  0.402826 -0.864446  \n",
       "505 -0.612640 -0.981871 -0.802418  1.175303  0.440616 -0.668397  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有的训练集和验证集都取出成为一个 numpy 的数组\n",
    "num_train = train.shape[0]\n",
    "\n",
    "train_features = all_features[:num_train].values\n",
    "\n",
    "train_labels = train.price.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def get_model():\n",
    "    # todo: 使用 nn.Sequential 来构造多层神经网络，注意第一层的输入\n",
    "    #m=nn.Linear(20,30)//我造的m是用来把拥有20种特征值的那种样本输入转变成拥有30种特征值的输出，不管你输入多少组，\n",
    "    #就是说不过输入多少样本，但你必须特征值的种类数是20。\n",
    "\n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(13, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以调整的超参\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "#use_gpu = False   # 没有gpu的改为False即可\n",
    "lr = 0.1\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# 回归任务一般用MSELoss, 分类用CrossEntropy\n",
    "# todo: 使用 mse 作为 loss 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#from utils import get_rmse_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([506, 13])\n",
      "torch.Size([506])\n"
     ]
    }
   ],
   "source": [
    "# todo: 将所有的 feature 和 label 都转成 torch 的 Tensor\n",
    "train_features = torch.Tensor(train_features)\n",
    "print(train_features.shape)\n",
    "\n",
    "\n",
    "train_labels = torch.Tensor(train_labels)\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个数据的迭代器\n",
    "def get_data(x, y, batch_size, shuffle):\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return DataLoader(dataset, batch_size, shuffle=shuffle, num_workers=0)#全部加载到主进程\n",
    "#dataset 数据集，batch_size加载的每批数据中的样本量，shuffle数据是否打乱，num_workers几线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000023CA0E64A48>\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(train_features,train_labels, batch_size, True)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([26])) that is different to the input size (torch.Size([26, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 6.362\n",
      "\n",
      "epoch: 10, train loss: 0.427\n",
      "\n",
      "epoch: 20, train loss: 0.415\n",
      "\n",
      "epoch: 30, train loss: 0.415\n",
      "\n",
      "epoch: 40, train loss: 0.415\n",
      "\n",
      "epoch: 50, train loss: 0.411\n",
      "\n",
      "epoch: 60, train loss: 0.414\n",
      "\n",
      "epoch: 70, train loss: 0.408\n",
      "\n",
      "epoch: 80, train loss: 0.409\n",
      "\n",
      "epoch: 90, train loss: 0.408\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_model(model, x_train, y_train, x_valid, y_valid, epochs, lr, weight_decay):\n",
    "#    if use_gpu:\n",
    "#       model = model.cuda()\n",
    "    metric_log = dict()\n",
    "    metric_log['train_loss'] = list()\n",
    "#    if x_valid is not None:\n",
    "#        metric_log['valid_loss'] = list()\n",
    "    \n",
    "    train_data = get_data(x_train, y_train, batch_size, True)\n",
    "    \n",
    "#    if x_valid is not None:\n",
    "#        valid_data = get_data(x_valid, y_valid, batch_size, False)\n",
    "#    else:\n",
    "#        valid_data = None\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr, weight_decay)# todo: 构建优化器，推荐使用 Adam，也可以尝试一下别的优化器\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # 训练模型\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        for data in train_data:\n",
    "            x, y = data\n",
    "#            if use_gpu:\n",
    "#                x = x.cuda()\n",
    "#                y = y.cuda()\n",
    "            x = Variable(x)\n",
    "            y = Variable(y)\n",
    "            \n",
    "            # todo: 前向传播\n",
    "            out = model(x)\n",
    "            # todo: 计算 loss\n",
    "            #torch.clamp(input, min, max, out=None),将输入input张量每个元素的范围限制到区间 [min,max]，返回结果到一个新张量。\n",
    "            clipped_out = torch.clamp(out, 1e-8, float('inf'))   \n",
    "            loss = torch.sqrt(criterion(clipped_out.log(), y.log()))\n",
    "            \n",
    "            \n",
    "            #criterion = nn.MSELoss(size_average=False).cuda()\n",
    "            #...\n",
    "            #loss = criterion(output, target)\n",
    "            #loss.backward()\n",
    "            # todo: 反向传播，更新参数\n",
    "            optimizer.zero_grad()#optimizer.zero_grad()意思是把梯度置零\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        metric_log['train_loss'].append(running_loss/len(train_data))\n",
    "        \n",
    "        \n",
    "        print_str = 'epoch: {}, train loss: {:.3f}'.format(e, metric_log['train_loss'][-1])\n",
    "        if (e ) % 10 == 0:\n",
    "            print(print_str)\n",
    "            print()\n",
    "       \n",
    "\n",
    "    # =======不要修改这里的内容========\n",
    "    # 可视化\n",
    "    figsize = (10, 5)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.plot(metric_log['train_loss'], color='red', label='train')\n",
    "#    if valid_data is not None:\n",
    "#        plt.plot(metric_log['valid_loss'], color='blue', label='valid')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "model = get_model()\n",
    "train_model(model, train_features, train_labels, None, None, epochs, lr, weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
